#!/bin/bash
#
# ðŸš€ AI Desktop Companion Launcher
# Double-cliquez sur ce fichier pour lancer l'assistant !
#
# Ce script:
# 1. VÃ©rifie que le serveur LLM (llama.cpp) tourne
# 2. Lance le backend FastAPI
# 3. Lance l'interface desktop avec Live2D
#

cd "$(dirname "$0")"

# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

echo -e "${GREEN}"
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘       ðŸŽ­ AI Desktop Companion - March 7th ðŸŽ­          â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo -e "${NC}"

# VÃ©rifier si le serveur LLM tourne
echo -e "${YELLOW}[1/3]${NC} VÃ©rification du serveur LLM..."
if curl -s http://localhost:8080/health > /dev/null 2>&1; then
    echo -e "  ${GREEN}âœ“${NC} Serveur LLM en cours d'exÃ©cution"
else
    echo -e "  ${RED}âœ—${NC} Serveur LLM non dÃ©tectÃ©"
    echo -e "  ${YELLOW}â†’${NC} DÃ©marrage automatique..."
    ./scripts/start_llm_server.sh --daemon
    sleep 3
    
    if curl -s http://localhost:8080/health > /dev/null 2>&1; then
        echo -e "  ${GREEN}âœ“${NC} Serveur LLM dÃ©marrÃ© !"
    else
        echo -e "  ${RED}âš ${NC} Impossible de dÃ©marrer le serveur LLM"
        echo "     VÃ©rifiez les logs ou lancez manuellement:"
        echo "     ./scripts/start_llm_server.sh"
        read -p "Appuyez sur EntrÃ©e pour continuer quand mÃªme..."
    fi
fi

# Activer l'environnement virtuel et lancer
echo -e "${YELLOW}[2/3]${NC} Activation de l'environnement Python..."
source venv/bin/activate

echo -e "${YELLOW}[3/3]${NC} Lancement de l'assistant..."
echo ""
echo -e "${GREEN}ðŸ’¡ Conseils:${NC}"
echo "   â€¢ Parlez dans votre micro pour interagir"
echo "   â€¢ Tapez du texte dans la bulle de chat"
echo "   â€¢ Fermez la fenÃªtre pour quitter"
echo ""

# Lancer avec --with-backend pour dÃ©marrer backend + frontend
python desktop.py --with-backend
