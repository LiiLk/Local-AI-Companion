# Configuration de l'Assistant IA
# Tu peux modifier ce fichier sans toucher au code !

# === LLM (Cerveau) ===
llm:
  # Quel type de LLM utiliser : "ollama", "openai", "groq"
  provider: "ollama"
  
  # Configuration Ollama
  ollama:
    model: "llama3.2:3b"      # Modèle à utiliser
    base_url: "http://localhost:11434"
  
  # Configuration OpenAI (pour plus tard)
  # openai:
  #   model: "gpt-4"
  #   api_key: "sk-..."  # Ou utiliser variable d'environnement

# === Personnalité de l'assistant ===
character:
  name: "Aria"
  # Le "system prompt" définit la personnalité de l'IA
  system_prompt: |
    Tu es Aria, une assistante IA amicale et serviable.
    Tu réponds de manière concise et claire en français.
    Tu es enthousiaste et positive.
    Tu aides l'utilisateur dans ses tâches quotidiennes.

# === TTS (Voix) ===
tts:
  # Provider TTS par défaut : "kokoro" (local, naturel) ou "edge" (cloud, gratuit)
  provider: "kokoro"
  
  # --- Kokoro TTS (100% local, haute qualité) ---
  # Voix disponibles: ff_siwis (FR), af_heart (US), bf_emma (UK), jf_alpha (JP)
  kokoro_voice: "ff_siwis"
  
  # --- Edge TTS (cloud Microsoft, fallback) ---
  voice: "fr-FR-DeniseNeural"
  # Autres voix Edge:
  # - fr-FR-HenriNeural (homme français)
  # - en-US-JennyNeural (femme américaine)  
  # - ja-JP-NanamiNeural (femme japonaise)
  
  rate: "+20%"   # Vitesse Edge TTS (-50% à +100%)
  pitch: "+0Hz"  # Hauteur Edge TTS (-50Hz à +50Hz)

# === ASR (Reconnaissance vocale) ===
asr:
  # Provider ASR : "whisper" (local, privé)
  provider: "whisper"
  
  # Taille du modèle Whisper
  # - tiny   : 39M params, ultra rapide, qualité basique
  # - base   : 74M params, rapide, bonne qualité (recommandé)
  # - small  : 244M params, moyen, très bonne qualité
  # - medium : 769M params, lent, excellente qualité
  # - large-v3: 1.5B params, très lent, qualité maximale
  model_size: "base"
  
  # Device: "cpu" ou "cuda" (GPU)
  # Note: Si problèmes cuDNN, utiliser "cpu"
  device: "cpu"
