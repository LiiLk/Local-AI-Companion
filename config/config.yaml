# AI Assistant Configuration
# You can modify this file without touching the code!

# === LLM (Brain) ===
llm:
  # Which LLM provider to use: "ollama" or "llamacpp"
  # - "ollama"   : Simple, pre-packaged models (llama3.2, mistral, etc.)
  # - "llamacpp" : Flexible, supports vision models (Jan-v2-VL, LLaVA, etc.)
  provider: "llamacpp"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ¦™ LLAMA.CPP SERVER (for Jan-v2-VL and vision models)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # Jan-v2-VL-high is a "thinking" model (8B params) that reflects before
  # responding. It uses Vulkan for GPU (no CUDA Toolkit needed).
  # 
  # Start the server before launching the assistant:
  #   ./scripts/start_llm_server.sh
  # or manually:
  #   cd ~/tools/llama-cpp && LD_LIBRARY_PATH="$PWD" ./llama-server \
  #     --model ~/models/jan-v2-vl-high/Jan-v2-VL-high-Q4_K_M.gguf \
  #     --mmproj ~/models/jan-v2-vl-high/mmproj-Jan-v2-VL-high.gguf \
  #     --host 0.0.0.0 --port 8080 --ctx-size 8192 --n-gpu-layers 99 \
  #     --jinja --no-context-shift
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  llamacpp:
    base_url: "http://localhost:8080"
    model_name: "jan-v2-vl-high"
    # Recommended parameters for Jan-v2-VL (thinking model)
    max_tokens: 2048        # Thinking models need more tokens
    temperature: 1.0        # Recommended by Jan for this model
    top_p: 0.95             # Top-p sampling
    top_k: 20               # Top-k sampling  
    presence_penalty: 1.5   # Reduces repetitions
  
  # Ollama configuration (fallback)
  ollama:
    model: "llama3.2:3b"      # Model to use
    base_url: "http://localhost:11434"

# === Assistant Personality ===
character:
  name: "Aria"
  # The "system prompt" defines the AI's personality
  system_prompt: |
    You are Aria, a friendly and helpful AI assistant.
    You respond concisely and clearly.
    You are enthusiastic and positive.
    You help the user with their daily tasks.

# === TTS (Voice) ===
tts:
  # Default TTS provider:
  # - "xtts"   : XTTS v2 (voice cloning, 17 languages, ~2.8GB VRAM) â­ RECOMMENDED
  # - "kokoro" : Kokoro 82M (local, natural, lightweight, no voice cloning)
  # - "edge"   : Edge TTS (Microsoft cloud, free)
  provider: "xtts"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ¤ XTTS v2 (Voice Cloning) - Best multilingual choice â­ RECOMMENDED
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # - ~467M params, ~2.8GB VRAM (coexists with Jan-v2-VL ~7GB = ~10GB total âœ…)
  # - Voice cloning with only 6 seconds of audio!
  # - 17 native languages: FR, EN, ES, DE, IT, PT, PL, TR, RU, NL, CS, AR, ZH, JA, HU, KO, HI
  # - 58 high-quality built-in speakers
  # - Streaming with latency < 200ms
  # - Model downloaded automatically (~1.9GB)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  xtts:
    # Default language
    language: "en"
    
    # Device: null = auto-detect (prefers CUDA if available)
    device: null
    
    # Built-in speaker (used if no voice cloning)
    # Some recommended voices:
    # - "Claribel Dervla" : Clear and natural female voice
    # - "Ana Florence" : Soft female voice
    # - "Craig Gutsy" : Energetic male voice
    # - "Zacharie Aimilios" : French male voice
    # - "Filip Traverse" : French male voice
    speaker: "Claribel Dervla"
    
    # ğŸ­ Voice Cloning (optional): uncomment to clone your voice
    # Only 6 seconds of clear audio needed!
    # speaker_wav: "~/voices/my_voice.wav"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸµ KOKORO TTS (100% local, lightweight, no voice cloning)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # - 82M params, ~300MB, natural quality
  # - Voices: ff_siwis (FR), af_heart (US), bf_emma (UK), jf_alpha (JP)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  kokoro_voice: "af_heart"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # â˜ï¸ EDGE TTS (Microsoft cloud, fallback)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  voice: "en-US-JennyNeural"
  # Other Edge voices:
  # - en-US-GuyNeural (American male)
  # - en-GB-SoniaNeural (British female)
  # - fr-FR-DeniseNeural (French female)
  # - ja-JP-NanamiNeural (Japanese female)
  
  rate: "+0%"    # Edge TTS speed (-50% to +100%)
  pitch: "+0Hz"  # Edge TTS pitch (-50Hz to +50Hz)

# === ASR (Speech Recognition) ===
asr:
  # Available ASR providers:
  # - "whisper"  : Local, CPU/GPU compatible, good for many languages with distilled models
  # - "canary"   : NVIDIA Canary 1B v2, best for long audio (6GB+ VRAM required)
  # - "parakeet" : NVIDIA Parakeet TDT 0.6B v3, fast and accurate (can run on CPU)
  # âš ï¸ With Jan-v2-VL (~7GB VRAM), use ASR on CPU to avoid OOM
  provider: "parakeet"
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ¦œ PARAKEET TDT 0.6B V3 (NVIDIA) - Fast and accurate â­ RECOMMENDED
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # - 600M params, ~2GB VRAM (lightweight!)
  # - Token-and-Duration Transducer (TDT) architecture
  # - Excellent on both short AND long audio
  # - 25 languages supported (including French, English, Spanish...)
  # - Automatic language detection
  # - Faster than Canary and Whisper large
  # - REQUIRES an NVIDIA GPU
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ¤ CANARY 1B V2 (NVIDIA) - State-of-the-art ASR
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # - Better accuracy than Whisper (WER ~5% for French)
  # - 25 European languages supported
  # - Automatic punctuation and capitalization
  # - REQUIRES an NVIDIA GPU with 6GB+ VRAM
  # - Faster than Whisper on GPU
  # âš ï¸ Less good on short conversational phrases
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  # Available Whisper models (if provider: "whisper"):
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # STANDARD MODELS (auto-download from OpenAI):
  # - tiny   : 39M params, very fast, low quality
  # - base   : 74M params, fast, medium quality
  # - small  : 244M params, GOOD COMPROMISE! Lightweight + good quality
  # - medium : 769M params, slow, very good quality
  # - large-v3: 1.5B params, very slow, best quality
  # - turbo  : 809M params, 6x faster than large-v3 (but sometimes hallucinates)
  # - distil-large-v3: 756M params, fast but ENGLISH ONLY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ‡«ğŸ‡· FRENCH-OPTIMIZED MODELS (downloaded to models/, gitignored):
  # - french-distil-dec4 : 0.8B params, Excellent FR quality, ~500MB download
  # - french-distil-dec2 : 0.8B params, Faster, very good FR quality
  # These models are fine-tuned on 2500+ hours of French by bofenghuang.
  # WER: 8.37% (much better than standard Whisper for French)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  model_size: "base"  # Standard model - good compromise
  
  # Language: "fr", "en", "auto" or empty "" for auto-detection
  language: "en"
  
  # Prompt to guide transcription (helps even with forced language)
  # Provides context about the expected conversation style.
  # Note: Only used by Whisper, Canary doesn't use prompts.
  prompt: "Transcription of a conversation with an AI assistant."
  
  # Device: "cpu" or "cuda" (GPU)
  # âš ï¸ With Jan-v2-VL on GPU, use "cpu" for Whisper to avoid OOM
  # Whisper base on CPU is fast enough (~1-2s per phrase)
  device: "cpu"
